{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- data source: http://www.manythings.org/anki/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, RNN, Multiply\n",
    "from tensorflow.keras.layers import RepeatVector, Dense, Activation, Lambda, Embedding, Reshape\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string \n",
    "import regex as re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import io\n",
    "import spacy\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# from tensorflow.python.framework.ops import disable_eager_execution\n",
    "# disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_en_de = pd.read_table('deu-eng/deu.txt', names=['eng', 'deu', 'attr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_en_de = df_en_de.drop('attr',axis = 1).rename(columns = {'eng':'english', 'deu':'german'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase all characters\n",
    "df_en_de['english'] = df_en_de['english'].apply(lambda x: x.lower())\n",
    "df_en_de['german'] = df_en_de['german'].apply(lambda x: x.lower())\n",
    "\n",
    "# Remove quotes\n",
    "df_en_de['english'] = df_en_de['english'].apply(lambda x: re.sub(\"'\", '', x))\n",
    "df_en_de['german'] = df_en_de['german'].apply(lambda x: re.sub(\"'\", '', x))\n",
    "\n",
    "# Set of all special characters\n",
    "exclude = set(string.punctuation) \n",
    "\n",
    "# Remove all the special characters\n",
    "df_en_de['english'] = df_en_de['english'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "df_en_de['german']=df_en_de['german'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "\n",
    "# Add start and end tokens to target sequences\n",
    "df_en_de['german'] = df_en_de['german'].apply(lambda x : 'START_ '+ x + ' _END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209317\n",
      "20932\n"
     ]
    }
   ],
   "source": [
    "max_len = 10\n",
    "\n",
    "pairs = df_en_de\n",
    "pairs['english_length'] = pairs['english'].apply(lambda x: len(x.split(' ')))\n",
    "pairs['german_length'] = pairs['german'].apply(lambda x: len(x.split(' ')))\n",
    "\n",
    "pairs = pairs[pairs['english_length'] <= max_len]\n",
    "pairs = pairs[pairs['german_length'] <= max_len]\n",
    "print(len(pairs))\n",
    "pairs = pairs.sample(frac = 0.1)\n",
    "print(len(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary of English\n",
    "all_en_words=set()\n",
    "for eng in pairs['english']:\n",
    "    for word in eng.split():\n",
    "        if word not in all_en_words:\n",
    "            all_en_words.add(word)\n",
    "\n",
    "# Vocabulary of German \n",
    "all_de_words=set()\n",
    "for de in pairs['german']:\n",
    "    for word in de.split():\n",
    "        if word not in all_de_words:\n",
    "            all_de_words.add(word)\n",
    "\n",
    "# Max Length of source sequence\n",
    "length_list=[]\n",
    "for l in pairs['english']:\n",
    "    length_list.append(len(l.split(' ')))\n",
    "max_length_src = np.max(length_list)\n",
    "\n",
    "# Max Length of target sequence\n",
    "length_list=[]\n",
    "for l in pairs['german']:\n",
    "    length_list.append(len(l.split(' ')))\n",
    "max_length_tar = np.max(length_list)\n",
    "\n",
    "\n",
    "input_words = sorted(list(all_en_words))\n",
    "target_words = sorted(list(all_de_words))\n",
    "\n",
    "# Calculate Vocab size for both source and target\n",
    "# Add 1 for zero padding\n",
    "num_encoder_tokens = len(all_en_words) + 1\n",
    "num_decoder_tokens = len(all_de_words) + 1\n",
    "\n",
    "# Create word to token dictionary for both source and target\n",
    "#input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
    "#target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])\n",
    "input_word_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
    "target_word_index = dict([(word, i+1) for i, word in enumerate(target_words)])\n",
    "\n",
    "# Create token to word dictionary for both source and target\n",
    "# reverse_input_token_index = dict((i, word) for word, i in input_token_index.items())\n",
    "# reverse_target_token_index = dict((i, word) for word, i in target_token_index.items())\n",
    "input_index_word = dict((i, word) for word, i in input_word_index.items())\n",
    "target_index_word = dict((i, word) for word, i in target_word_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = pairs['english'], pairs['german']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(X = X_train, y = y_train, batch_size = 128):\n",
    "    ''' Generate a batch of data '''\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):          # j = batch number\n",
    "            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32') # (m, max_len)\n",
    "            \n",
    "            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32') # (m, max_len)\n",
    "\n",
    "            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')    # (m, max_len, num_decoder_tokens)\n",
    "            \n",
    "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
    "                for t, word in enumerate(input_text.split()):\n",
    "                    encoder_input_data[i, t] = input_word_index[word] # encoder input seq\n",
    "                for t, word in enumerate(target_text.split()):\n",
    "                    if t<len(target_text.split())-1:\n",
    "                        decoder_input_data[i, t] = target_word_index[word] # decoder input seq\n",
    "                    if t>0:\n",
    "                        # decoder target sequence (one hot encoded)\n",
    "                        # does not include the START_ token\n",
    "                        # Offset by one timestep\n",
    "                        decoder_target_data[i, t - 1, target_word_index[word]] = 1. \n",
    "                        \"\"\" This should be target_token_index[word] - 1\"\"\"\n",
    "            # decoder_target_data = np.transpose(decoder_target_data, axes = [1, 0, 2])\n",
    "            # decoder_target_data = list(decoder_target_data)\n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10250"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tx = max_len\n",
    "Ty = max_len\n",
    "repeator = RepeatVector(Tx)\n",
    "concatenator = Concatenate(axis = -1)\n",
    "densor1 = Dense(10, activation = 'tanh')\n",
    "densor2 = Dense (1, activation = 'relu')\n",
    "dotor = Dot(axes = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_step_attention (h, s_prev):\n",
    "\n",
    "    # calculate the Context vector for one time-step of decoder\n",
    "\n",
    "    # h = (m, Tx, n_h)\n",
    "    # s_prev = (m, n_s)\n",
    "    # returns: context – we will then use [context; y_prev] as input of Decoder\n",
    "\n",
    "    s_prev = repeator(s_prev)                   # (m, Tx, n_s)\n",
    "    concat = concatenator([h, s_prev])          # (m, Tx, n_h + n_s)\n",
    "    e = densor1 (concat)                        # (m, Tx, 10)\n",
    "    energies = densor2 (e)                      # (m, Tx, 1)\n",
    "    alphas = tf.nn.softmax(energies, axis = 1)  # (m, Tx, 1)\n",
    "    context = dotor([alphas, h])                # alphas = (m, Tx, 1)\n",
    "                                                # h = (m, Tx, n_h)\n",
    "                                                # (m, 1, n_h)\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_emb_dim = 300\n",
    "y_emb_dim = 300\n",
    "\n",
    "n_h = 200\n",
    "n_s = 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-01 11:10:22.114934: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "post_attention_LSTM_cell = LSTM(n_s, return_state = True)\n",
    "output_layer = Dense(num_decoder_tokens, activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10250 (None, 10, 10250)\n"
     ]
    }
   ],
   "source": [
    "# h = hidden state of pre-attention RNN layer\n",
    "# s = hidden state of post-attention RNN layer\n",
    "\n",
    "x_inputs = Input(shape = (Tx,))                         # (None, Tx) = (m, Tx)\n",
    "x_emb_layer = Embedding(\n",
    "                            num_encoder_tokens, \n",
    "                            x_emb_dim, \n",
    "                            mask_zero = True\n",
    "                            )      \n",
    "x_emb = x_emb_layer(x_inputs)                         # (None, Tx, x_emb_dim) = (m, Tx, x_emb_dim)\n",
    "\n",
    "y_inputs = Input(shape = (Ty,))                         # (None, Ty) = (m, Ty)\n",
    "y_emb_layer = Embedding(\n",
    "                          num_decoder_tokens,\n",
    "                          y_emb_dim,\n",
    "                          mask_zero = True\n",
    "                          )\n",
    "y_emb = y_emb_layer(y_inputs)                         # (None, Ty, y_emb_dim) = (m, Ty, y_emb_dim)\n",
    "\n",
    "\n",
    "# pass x embeddings through pre-attention LSTM layer\n",
    "# here, we will use the final hidden-state as the initial post-attention LSTM hidden state\n",
    "\n",
    "enc_lstm_layer = LSTM(n_h, return_sequences=True, return_state = True)\n",
    "h_enc, s_enc, c_enc = enc_lstm_layer(x_emb)                             # h_enc = (None, Tx, n_h) = (m, Tx, n_h)\n",
    "                                                                        # s_enc = (None, n_h) = (m, n_h)\n",
    "                                                                        # c_enc = (None, n_h) = (m, n_h)\n",
    "# s<0> and c<0> for decoder = s<ty> and c<ty> for encoder\n",
    "s_dec = s_enc\n",
    "c_dec = c_enc                                                              \n",
    "\n",
    "outputs = []\n",
    "for t in range(Ty):\n",
    "    context = one_step_attention(h_enc, s_dec)                                            # context = (m, 1, n_h)\n",
    "    concat = Concatenate(axis = -1)([context, tf.expand_dims(y_emb[:,t,:],1)])            # concat = (m, 1, n_h + y_emb_dim)\n",
    "    \n",
    "    # update decoder LSTM hidden state (s) and cell state (c)\n",
    "    _, s_dec, c_dec = post_attention_LSTM_cell (initial_state = [s_dec, c_dec], inputs = concat)        # s = (None, Ty, n_s)\n",
    "    \n",
    "    # pass decoder LSTM hidden state (s) through output layer to get y prediction\n",
    "    out = output_layer(s_dec)                                                                   # out = (m, num_decoder_tokens)\n",
    "    outputs.append(out)\n",
    "                                                            \n",
    "outputs = tf.stack(outputs, axis = 1)\n",
    "print(num_decoder_tokens, outputs.shape)\n",
    "model = Model(inputs = [x_inputs, y_inputs], outputs = outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer= 'Adam', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = len(X_train) # Total Training samples\n",
    "val_samples = len(X_test) # total validation samples\n",
    "batch_size = 128\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "130/130 [==============================] - 37s 284ms/step - loss: 3.3899 - acc: 0.1473 - val_loss: 3.4142 - val_acc: 0.1528\n",
      "Epoch 2/5\n",
      "130/130 [==============================] - 37s 282ms/step - loss: 3.1734 - acc: 0.1627 - val_loss: 3.2692 - val_acc: 0.1651\n",
      "Epoch 3/5\n",
      "130/130 [==============================] - 37s 282ms/step - loss: 3.0050 - acc: 0.1791 - val_loss: 3.1606 - val_acc: 0.1849\n",
      "Epoch 4/5\n",
      "130/130 [==============================] - 38s 294ms/step - loss: 2.8388 - acc: 0.2028 - val_loss: 3.0348 - val_acc: 0.2028\n",
      "Epoch 5/5\n",
      "130/130 [==============================] - 37s 282ms/step - loss: 2.6812 - acc: 0.2191 - val_loss: 2.9283 - val_acc: 0.2144\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(generate_batch(), \n",
    "                    steps_per_epoch=train_samples//batch_size, \n",
    "                    epochs = 5,\n",
    "                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n",
    "                    validation_steps = val_samples // batch_size, \n",
    "                    verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_inputs defined above as Input\n",
    "# h_enc, s_enc, c_enc also defined above\n",
    "encoder_model = Model(inputs = x_inputs, outputs = [h_enc, s_enc, c_enc])\n",
    "\n",
    "# x_inputs = (None, Tx)\n",
    "\n",
    "# h_enc = (None, Tx, n_h)\n",
    "# s_enc = (None, n_s) \n",
    "# c_enc = (None, n_s) \n",
    "\n",
    "# The below three decoder inputs will come from encoder_model.predict()\n",
    "decoder_input_h = Input(shape = (Tx, n_h))               # (None, Tx, n_h) \n",
    "decoder_input_s = Input(shape=(n_s, ))                    # (None, n_s) \n",
    "decoder_input_c = Input(shape = (n_s,))                   # (None, n_s) \n",
    "\n",
    "# y_emb_2 will be our y_pred at t-1\n",
    "y_inp_2 = Input(shape = (None,))                        # (None, None) = (m, Ty)\n",
    "y_emb_2 = y_emb_layer(y_inp_2)                          # (None, None, y_emb_dim) = (m, Ty, y_emb_dim)\n",
    "\n",
    "# Use decoder_input_s and decoder_input_h to compute context vector\n",
    "context = one_step_attention(decoder_input_h, decoder_input_s)    # (m, 1, n_h)\n",
    "\n",
    "# concatenate context with y_emb_2\n",
    "concat2 = Concatenate(axis = -1)([context, tf.expand_dims(y_emb_2[:,-1,:],1)])                       \n",
    "                                                        # concat2 = (None, 1, n_h + y_emb_dim)\n",
    "\n",
    "# Feed concat2 as input; decoder_input_s and decoder_input_c as initial state\n",
    "_, decoder_output_s, decoder_output_c = post_attention_LSTM_cell (\n",
    "                                                        initial_state = [decoder_input_s, decoder_input_c], \n",
    "                                                        inputs = concat2\n",
    "                                                        )     \n",
    "                                            # decoder_output_s = (None, n_s) \n",
    "                                            # decoder_output_c = (None, n_s) \n",
    "\n",
    "#decoder_output_s = tf.expand_dims(decoder_output_s, 1)      # decoder_output_s = (None, 1, n_s)\n",
    "#decoder_output_c = tf.expand_dims(decoder_output_c, 1)      # decoder_output_c = (None, 1, n_s)\n",
    "decoder_output_y = output_layer(tf.expand_dims(decoder_output_s,1))           # (None, 1, num_decoder_tokens)\n",
    "\n",
    "decoder_model = Model(inputs = [decoder_input_h, decoder_input_s, decoder_input_c, y_inp_2],\n",
    "                         outputs = [decoder_output_y, decoder_output_s, decoder_output_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_sequence):\n",
    "\n",
    "    # input_sequence = (1, max_len)\n",
    "    \n",
    "    # get hidden states + final hidden state + final cell state from encoder \n",
    "    h_enc_pred, s_enc_pred, c_enc_pred = encoder_model.predict(input_sequence)\n",
    "    \n",
    "    # define y_pred at time 0    \n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0,0] = target_word_index['START_']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "\n",
    "    # initialise hidden state and cell state input for decoder\n",
    "    decoder_s_pred = s_enc_pred                         # (None, n_h) = (m, n_h)\n",
    "    decoder_c_pred = c_enc_pred                         # (None, n_h) = (m, n_h)\n",
    "    \n",
    "    while not stop_condition:\n",
    "        \n",
    "        decoder_y_pred, decoder_s_pred, decoder_c_pred = decoder_model.predict([h_enc_pred, decoder_s_pred, decoder_c_pred, target_seq])  \n",
    "        y_index = np.argmax(decoder_y_pred[0,-1,:])\n",
    "        y_word = target_index_word[y_index]\n",
    "        decoded_sentence += ' ' + y_word\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (y_word == '_END' or\n",
    "           len(decoded_sentence.split()) > max_len):\n",
    "            stop_condition = True\n",
    "        \n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = y_index\n",
    "\n",
    "    return decoded_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_seq(sentence):\n",
    "    \"\"\"\n",
    "    sentence = string\n",
    "    \"\"\"\n",
    "    \n",
    "    encoder_input_data = np.zeros((1, max_len))     # (1, max_len)\n",
    "    \n",
    "    sentence = sentence.lower().split()\n",
    "    #print(sentence)\n",
    "    for j, word in enumerate(sentence):\n",
    "        encoder_input_data[0,j] = input_word_index[word]        # (1, max_len)\n",
    "    # print(encoder_input_data.shape)\n",
    "    return encoder_input_data                           # (1, max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('poets write poems', ' lass den tisch gegessen _END')\n",
      "('he admired my new car', ' er sieht mein auto hat _END')\n",
      "('tom was offended', ' tom war nervös _END')\n",
      "('tom is a friend of a friend of mine', ' tom ist ein bisschen ein guter freund _END')\n",
      "('plutonium239 has a halflife of 24100 years', ' plutonium239 hat eine hohe von des gegessen _END')\n",
      "('i think tom is drunk', ' ich glaube tom ist gerade glücklich _END')\n",
      "('cardboard is stronger than paper', ' pappe ist schwerer als meine mutter _END')\n",
      "('a good idea occurred to him', ' ein buch ist von ihm sehr geholfen _END')\n",
      "('tell me a joke', ' gib mir ein hund _END')\n",
      "('i just want to sleep', ' ich will nur im bett _END')\n"
     ]
    }
   ],
   "source": [
    "sentences = list(X_train.iloc[:10].values)          # list of sentences\n",
    "\n",
    "translations = []\n",
    "for sentence in sentences:\n",
    "    seq = sentence_to_seq(sentence)             # seq = (1, max_len)\n",
    "    #print(seq, seq.shape)\n",
    "    translation = decode_sequence(seq)\n",
    "    translations.append(translation)\n",
    "\n",
    "sentence_translation_pairs = zip (sentences, translations)\n",
    "for elem in sentence_translation_pairs:\n",
    "    print (elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('deep_learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "62f0de500e91648e2f1c8ecd59ca95f97588cc062e27f09a44618e0428f97b74"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
