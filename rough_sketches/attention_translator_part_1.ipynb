{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- data source: http://www.manythings.org/anki/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, RNN, Multiply\n",
    "from tensorflow.keras.layers import RepeatVector, Dense, Activation, Lambda, Embedding, Reshape\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string \n",
    "import regex as re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import io\n",
    "import spacy\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# from tensorflow.python.framework.ops import disable_eager_execution\n",
    "# disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_en_de = pd.read_table('deu-eng/deu.txt', names=['eng', 'deu', 'attr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_en_de = df_en_de.drop('attr',axis = 1).rename(columns = {'eng':'english', 'deu':'german'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase all characters\n",
    "df_en_de['english'] = df_en_de['english'].apply(lambda x: x.lower())\n",
    "df_en_de['german'] = df_en_de['german'].apply(lambda x: x.lower())\n",
    "\n",
    "# Remove quotes\n",
    "df_en_de['english'] = df_en_de['english'].apply(lambda x: re.sub(\"'\", '', x))\n",
    "df_en_de['german'] = df_en_de['german'].apply(lambda x: re.sub(\"'\", '', x))\n",
    "\n",
    "# Set of all special characters\n",
    "exclude = set(string.punctuation) \n",
    "\n",
    "# Remove all the special characters\n",
    "df_en_de['english'] = df_en_de['english'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "df_en_de['german']=df_en_de['german'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "\n",
    "# Add start and end tokens to target sequences\n",
    "df_en_de['german'] = df_en_de['german'].apply(lambda x : 'START_ '+ x + ' _END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209317\n",
      "20932\n"
     ]
    }
   ],
   "source": [
    "max_len = 10\n",
    "\n",
    "pairs = df_en_de\n",
    "pairs['english_length'] = pairs['english'].apply(lambda x: len(x.split(' ')))\n",
    "pairs['german_length'] = pairs['german'].apply(lambda x: len(x.split(' ')))\n",
    "\n",
    "pairs = pairs[pairs['english_length'] <= max_len]\n",
    "pairs = pairs[pairs['german_length'] <= max_len]\n",
    "print(len(pairs))\n",
    "pairs = pairs.sample(frac = 0.1)\n",
    "print(len(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary of English\n",
    "all_en_words=set()\n",
    "for eng in pairs['english']:\n",
    "    for word in eng.split():\n",
    "        if word not in all_en_words:\n",
    "            all_en_words.add(word)\n",
    "\n",
    "# Vocabulary of German \n",
    "all_de_words=set()\n",
    "for de in pairs['german']:\n",
    "    for word in de.split():\n",
    "        if word not in all_de_words:\n",
    "            all_de_words.add(word)\n",
    "\n",
    "# Max Length of source sequence\n",
    "length_list=[]\n",
    "for l in pairs['english']:\n",
    "    length_list.append(len(l.split(' ')))\n",
    "max_length_src = np.max(length_list)\n",
    "\n",
    "# Max Length of target sequence\n",
    "length_list=[]\n",
    "for l in pairs['german']:\n",
    "    length_list.append(len(l.split(' ')))\n",
    "max_length_tar = np.max(length_list)\n",
    "\n",
    "\n",
    "input_words = sorted(list(all_en_words))\n",
    "target_words = sorted(list(all_de_words))\n",
    "\n",
    "# Calculate Vocab size for both source and target\n",
    "# Add 1 for zero padding\n",
    "num_encoder_tokens = len(all_en_words) + 1\n",
    "num_decoder_tokens = len(all_de_words) + 1\n",
    "\n",
    "\n",
    "\n",
    "# Create word to token dictionary for both source and target\n",
    "#input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
    "#target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])\n",
    "input_word_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
    "target_word_index = dict([(word, i+1) for i, word in enumerate(target_words)])\n",
    "\n",
    "# Create token to word dictionary for both source and target\n",
    "# reverse_input_token_index = dict((i, word) for word, i in input_token_index.items())\n",
    "# reverse_target_token_index = dict((i, word) for word, i in target_token_index.items())\n",
    "input_index_word = dict((i, word) for word, i in input_word_index.items())\n",
    "target_index_word = dict((i, word) for word, i in target_word_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = pairs['english'], pairs['german']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(X = X_train, y = y_train, batch_size = 128):\n",
    "    ''' Generate a batch of data '''\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):          # j = batch number\n",
    "            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32') # (m, max_len)\n",
    "            \n",
    "            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32') # (m, max_len)\n",
    "\n",
    "            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')    # (m, max_len, num_decoder_tokens)\n",
    "            \n",
    "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
    "                for t, word in enumerate(input_text.split()):\n",
    "                    encoder_input_data[i, t] = input_word_index[word] # encoder input seq\n",
    "                for t, word in enumerate(target_text.split()):\n",
    "                    if t<len(target_text.split())-1:\n",
    "                        decoder_input_data[i, t] = target_word_index[word] # decoder input seq\n",
    "                    if t>0:\n",
    "                        # decoder target sequence (one hot encoded)\n",
    "                        # does not include the START_ token\n",
    "                        # Offset by one timestep\n",
    "                        decoder_target_data[i, t - 1, target_word_index[word]] = 1. \n",
    "                        \"\"\" This should be target_token_index[word] - 1\"\"\"\n",
    "            # decoder_target_data = np.transpose(decoder_target_data, axes = [1, 0, 2])\n",
    "            # decoder_target_data = list(decoder_target_data)\n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tx = max_len\n",
    "Ty = max_len\n",
    "repeator = RepeatVector(Tx)\n",
    "concatenator = Concatenate(axis = -1)\n",
    "densor1 = Dense(10, activation = 'tanh')\n",
    "densor2 = Dense (1, activation = 'relu')\n",
    "dotor = Dot(axes = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_step_attention (h, s_prev):\n",
    "\n",
    "    # calculate the Context vector for one time-step of decoder\n",
    "\n",
    "    # h = (m, Tx, n_h)\n",
    "    # s_prev = (m, n_s)\n",
    "    # returns: context – we will then use [context; y_prev] as input of Decoder\n",
    "\n",
    "    s_prev = repeator(s_prev)                   # (m, Tx, n_s)\n",
    "    concat = concatenator([h, s_prev])          # (m, Tx, n_h + n_s)\n",
    "    e = densor1 (concat)                        # (m, Tx, 10)\n",
    "    energies = densor2 (e)                      # (m, Tx, 1)\n",
    "    alphas = tf.nn.softmax(energies, axis = 1)  # (m, Tx, 1)\n",
    "    context = dotor([alphas, h])                # alphas = (m, Tx, 1)\n",
    "                                                # h = (m, Tx, n_h)\n",
    "                                                # (m, 1, n_h)\n",
    "\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_emb_dim = 300\n",
    "y_emb_dim = 300\n",
    "\n",
    "n_h = 200\n",
    "n_s = 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-31 11:37:48.214739: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "post_attention_LSTM_cell = LSTM(n_s, return_state = True)\n",
    "output_layer = Dense(num_decoder_tokens, activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = tf.Variable([[[1,2,3],[4,5,6],[7,8,9]], [[1,2,3],[4,5,6],[7,8,9]]])\n",
    "tensor[:,0,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ten1 = tf.constant([[1,2,3], [4,5,6]])\n",
    "ten1idx = tf.argmax(ten1, axis = -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 10, 10160)\n"
     ]
    }
   ],
   "source": [
    "# h = hidden state of pre-attention RNN layer\n",
    "# s = hidden state of post-attention RNN layer\n",
    "\n",
    "x_inputs = Input(shape = (Tx,))                         # (None, Tx) = (m, Tx)\n",
    "x_emb_layer = Embedding(\n",
    "                            num_encoder_tokens, \n",
    "                            x_emb_dim, mask_zero = True\n",
    "                            )      \n",
    "x_emb = x_emb_layer(x_inputs)                         # (None, Tx, x_emb_dim) = (m, Tx, x_emb_dim)\n",
    "\n",
    "y_inputs = Input(shape = (Ty,))                         # (None, Ty) = (m, Ty)\n",
    "y_emb_layer = Embedding(\n",
    "                          num_decoder_tokens,\n",
    "                          y_emb_dim,\n",
    "                          mask_zero = True\n",
    "                          )\n",
    "y_emb = y_emb_layer(y_inputs)                         # (None, Ty, y_emb_dim) = (m, Ty, y_emb_dim)\n",
    "\n",
    "\n",
    "# pass x embeddings through pre-attention LSTM layer\n",
    "# here, we will use the final hidden-state as the initial post-attention LSTM hidden state\n",
    "\n",
    "enc_lstm_layer = LSTM(n_h, return_sequences=True, return_state = True)\n",
    "h, s, c = enc_lstm_layer(x_emb)                                           # h = (None, Tx, n_h) = (m, Tx, n_h)\n",
    "                                                                        # s = (None, Tx, n_h) = (m, n_h)\n",
    "                                                                        # c = (None, Tx, n_h) = (m, n_h)\n",
    "\n",
    "# store pre-attention LSTM's hidden state and cell state for later\n",
    "h_enc = h\n",
    "s0 = s\n",
    "c0 = c                                                                        \n",
    "\n",
    "\n",
    "outputs = []\n",
    "for t in range(Ty):\n",
    "    context = one_step_attention(h, s)                                                    # context = (m, 1, n_h)\n",
    "    concat = Concatenate(axis = -1)([context, tf.expand_dims(y_emb[:,t,:],1)])            # concat = (m, 1, n_h + y_emb_dim)\n",
    "    \n",
    "    # update decoder LSTM hidden state (s) and cell state (c)\n",
    "    s, _, c = post_attention_LSTM_cell (initial_state = [s, c], inputs = concat)        # s = (None, Ty, n_s)\n",
    "    \n",
    "    # pass decoder LSTM hidden state (s) through output layer to get y prediction\n",
    "    out = output_layer(s)                                                                   # out = (m, num_decoder_tokens)\n",
    "    outputs.append(out)\n",
    "                                                            \n",
    "outputs = tf.stack(outputs, axis = 1)\n",
    "print(outputs.shape)\n",
    "model = Model(inputs = [x_inputs, y_inputs], outputs = outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer= 'Adam', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = len(X_train) # Total Training samples\n",
    "val_samples = len(X_test) # total validation samples\n",
    "batch_size = 128\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "130/130 [==============================] - 53s 287ms/step - loss: 4.1117 - acc: 0.1174 - val_loss: 3.7308 - val_acc: 0.1230\n",
      "Epoch 2/10\n",
      "130/130 [==============================] - 33s 256ms/step - loss: 3.5886 - acc: 0.1287 - val_loss: 3.6346 - val_acc: 0.1340\n",
      "Epoch 3/10\n",
      "130/130 [==============================] - 34s 258ms/step - loss: 3.4059 - acc: 0.1439 - val_loss: 3.4404 - val_acc: 0.1514\n",
      "Epoch 4/10\n",
      "130/130 [==============================] - 34s 259ms/step - loss: 3.1905 - acc: 0.1627 - val_loss: 3.2899 - val_acc: 0.1729\n",
      "Epoch 5/10\n",
      "130/130 [==============================] - 34s 259ms/step - loss: 2.9960 - acc: 0.1853 - val_loss: 3.1468 - val_acc: 0.1899\n",
      "Epoch 6/10\n",
      "130/130 [==============================] - 34s 259ms/step - loss: 2.8255 - acc: 0.2030 - val_loss: 3.0390 - val_acc: 0.2023\n",
      "Epoch 7/10\n",
      "130/130 [==============================] - 33s 256ms/step - loss: 2.6732 - acc: 0.2180 - val_loss: 2.9355 - val_acc: 0.2149\n",
      "Epoch 8/10\n",
      "130/130 [==============================] - 33s 256ms/step - loss: 2.5278 - acc: 0.2337 - val_loss: 2.8498 - val_acc: 0.2271\n",
      "Epoch 9/10\n",
      "130/130 [==============================] - 33s 257ms/step - loss: 2.3888 - acc: 0.2486 - val_loss: 2.7707 - val_acc: 0.2367\n",
      "Epoch 10/10\n",
      "130/130 [==============================] - 33s 257ms/step - loss: 2.2583 - acc: 0.2627 - val_loss: 2.7080 - val_acc: 0.2452\n"
     ]
    }
   ],
   "source": [
    "# history = model.fit(generate_batch(), \n",
    "#                     steps_per_epoch=train_samples//batch_size, \n",
    "#                     epochs = epochs,\n",
    "#                     verbose = 1)\n",
    "\n",
    "history = model.fit(generate_batch(), \n",
    "                    steps_per_epoch=train_samples//batch_size, \n",
    "                    epochs = epochs,\n",
    "                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n",
    "                    validation_steps = val_samples // batch_size, \n",
    "                    verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And then you train the moddle to get the optimised weights for \n",
    "# x_emb_layer, y_emb_layer, LSTM (pre-attention), post_attention_LSTM_cell\n",
    "\n",
    "# OK, so after training, you have \n",
    "# x_emb_layer, y_emb_layer, LSTM(pre-attention), post_attention_LSTM_cell\n",
    "\n",
    "# So you'll just have to get all the h state vectors for all Tx time-steps at once\n",
    "# this gives you context vector for each Ty time step\n",
    "# Then using context vector + y_prev, you predict one y at a time. \n",
    "\n",
    "# Pass in your source sentence as (1, Tx) into encoder_model:\n",
    "encoder_model = Model(x_inputs, [h_enc, s0, c0])\n",
    "\n",
    "# x_inputs already defined - (None, Tx) = (m, Tx)\n",
    "# y_inputs already defined - (None, Ty) = (m, Ty)\n",
    "# but we actually want to input one time-step at a time, so need shape to be (None, None)\n",
    "# x_emb_layer already defined - after embedding, would be: (None, Tx, x_emb_dim) = (m, Tx, x_emb_dim)\n",
    "# y_emb_layer already defined - after embedding, would be: (None, Ty, y_emb_dim) = (m, Ty, y_emb_dim)\n",
    "\n",
    "\n",
    "# The below three decoder inputs will come from encoder_model.predict()\n",
    "decoder_input_s = Input(shape=(n_s, ))             # (None, n_s) = (m, n_s)\n",
    "decoder_input_c = Input(shape = (n_s,))          # (None, n_s) = (m, n_s)\n",
    "decoder_input_h = Input (shape = (Tx, n_h))               # (None, Tx, n_h) = (m, Tx, n_h)\n",
    "\n",
    "# Use decoder_input_s and decoder_input_h to compute context vector\n",
    "context = one_step_attention(decoder_input_h, decoder_input_s)    # (m, 1, n_h)\n",
    "\n",
    "# y_emb_2 will be our y_pred at t-1\n",
    "y_inp_2 = Input(shape = (None,))                        # (None, None) = (m, Ty)\n",
    "y_emb_2 = y_emb_layer(y_inp_2)                          # (None, None, y_emb_dim) = (m, Ty, y_emb_dim)\n",
    "\n",
    "# concatenate context with y_emb_2\n",
    "concat2 = Concatenate(axis = -1)([context, \n",
    "                                tf.expand_dims(y_emb_2[:,0,:],1)]\n",
    "                                )                       # (m, 1, n_h + y_emb_dim)\n",
    "\n",
    "# Feed concat2 as input; decoder_input_s and decoder_input_c as initial state\n",
    "_, decoder_output_s, decoder_output_c = post_attention_LSTM_cell (\n",
    "                                                        initial_state = [decoder_input_s, decoder_input_c], \n",
    "                                                        inputs = concat2\n",
    "                                                        )     \n",
    "                                            # decoder_output_s = (None, n_s) = (m, n_s)\n",
    "                                            # decoder_output_c = (None, n_c) = (m, n_s)\n",
    "\n",
    "decoder_output_s = tf.expand_dims(decoder_output_s, 1)      # decoder_output_s = (None, 1, n_s)\n",
    "decoder_output_c = tf.expand_dims(decoder_output_c, 1)      # decoder_output_c = (None, 1, n_s)\n",
    "\n",
    "decoder_output_y = output_layer(decoder_output_s)           # (m, 1, num_decoder_tokens)\n",
    "\n",
    "# inputs:\n",
    "# decoder_input_s\n",
    "# decoder_input_c\n",
    "# decoder_input_h\n",
    "# y_inp_2\n",
    "# outputs:\n",
    "# decoder_output_y, decoder_output_s, decoder_output_c\n",
    "\n",
    "decoder_model = Model(inputs = [decoder_input_s, decoder_input_c, decoder_input_h, y_inp_2],\n",
    "                         outputs = [decoder_output_y, decoder_output_s, decoder_output_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_sequence):\n",
    "    # get hidden states + final hidden state + final cell state from encoder \n",
    "    h_enc, s0, c0 = encoder_model.predict(input_sequence)\n",
    "\n",
    "    # define y_pred at time 0    \n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0,0] = target_word_index['START_']\n",
    "    \n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "\n",
    "    # initialise hidden state and cell state input for decoder\n",
    "    decoder_s = s0                         # (None, n_h) = (m, n_h)\n",
    "    decoder_c = c0                         # (None, n_h) = (m, n_h)\n",
    "\n",
    "    while not stop_condition:\n",
    "        decoder_output_y, \n",
    "        decoder_s, \n",
    "        decoder_c = decoder_model.predict([decoder_s, decoder_c, h_enc, target_seq])\n",
    "        print(type(decoder_output_y), decoder_output_y.shape)\n",
    "        y_index = np.argmax(decoder_output_y[0,-1,:])\n",
    "        y_word = target_index_word[y_index]\n",
    "        decoded_sentence += ' ' + y_word\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (y_word == '_END' or\n",
    "           len(decoded_sentence) > max_len):\n",
    "            stop_condition = True\n",
    "        \n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = y_index\n",
    "\n",
    "    return decoded_sentence\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_seq(sentence):\n",
    "    \"\"\"\n",
    "    sentence = string\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    encoder_input_data = np.zeros((1, max_len))\n",
    "    \n",
    "    sentence = sentence.lower().split()\n",
    "    #print(sentence)\n",
    "    for j, word in enumerate(sentence):\n",
    "        encoder_input_data[0,j] = input_word_index[word]\n",
    "    return encoder_input_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'keras.engine.keras_tensor.KerasTensor'> (None, 1, 10160)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "You are passing KerasTensor(type_spec=TensorSpec(shape=(10160,), dtype=tf.float32, name=None), name='tf.__operators__.getitem_11/strided_slice:0', description=\"created by layer 'tf.__operators__.getitem_11'\"), an intermediate Keras symbolic input/output, to a TF API that does not allow registering custom dispatchers, such as `tf.cond`, `tf.function`, gradient tapes, or `tf.map_fn`. Keras Functional model construction only supports TF API calls that *do* support dispatching, such as `tf.math.add` or `tf.reshape`. Other APIs cannot be called directly on symbolic Kerasinputs/outputs. You can work around this limitation by putting the operation in a custom Keras layer `call` and calling that layer on this symbolic input/output.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/Oh/Desktop/Machine_Learning/deep_learning/pet_projects/Attention_translator/attention_translator_part_1.ipynb Cell 23\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Oh/Desktop/Machine_Learning/deep_learning/pet_projects/Attention_translator/attention_translator_part_1.ipynb#ch0000024?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m sentence \u001b[39min\u001b[39;00m sentences:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Oh/Desktop/Machine_Learning/deep_learning/pet_projects/Attention_translator/attention_translator_part_1.ipynb#ch0000024?line=4'>5</a>\u001b[0m     seq \u001b[39m=\u001b[39m sentence_to_seq(sentence)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/Oh/Desktop/Machine_Learning/deep_learning/pet_projects/Attention_translator/attention_translator_part_1.ipynb#ch0000024?line=5'>6</a>\u001b[0m     translation \u001b[39m=\u001b[39m decode_sequence(seq)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Oh/Desktop/Machine_Learning/deep_learning/pet_projects/Attention_translator/attention_translator_part_1.ipynb#ch0000024?line=6'>7</a>\u001b[0m     translations\u001b[39m.\u001b[39mappend(translation)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Oh/Desktop/Machine_Learning/deep_learning/pet_projects/Attention_translator/attention_translator_part_1.ipynb#ch0000024?line=8'>9</a>\u001b[0m sentence_translation_pairs \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m (sentences, translations)\n",
      "\u001b[1;32m/Users/Oh/Desktop/Machine_Learning/deep_learning/pet_projects/Attention_translator/attention_translator_part_1.ipynb Cell 23\u001b[0m in \u001b[0;36mdecode_sequence\u001b[0;34m(input_sequence)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Oh/Desktop/Machine_Learning/deep_learning/pet_projects/Attention_translator/attention_translator_part_1.ipynb#ch0000024?line=18'>19</a>\u001b[0m decoder_c \u001b[39m=\u001b[39m decoder_model\u001b[39m.\u001b[39mpredict([decoder_s, decoder_c, h_enc, target_seq])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Oh/Desktop/Machine_Learning/deep_learning/pet_projects/Attention_translator/attention_translator_part_1.ipynb#ch0000024?line=19'>20</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mtype\u001b[39m(decoder_output_y), decoder_output_y\u001b[39m.\u001b[39mshape)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/Oh/Desktop/Machine_Learning/deep_learning/pet_projects/Attention_translator/attention_translator_part_1.ipynb#ch0000024?line=20'>21</a>\u001b[0m y_index \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49margmax(decoder_output_y[\u001b[39m0\u001b[39;49m,\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m,:])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Oh/Desktop/Machine_Learning/deep_learning/pet_projects/Attention_translator/attention_translator_part_1.ipynb#ch0000024?line=21'>22</a>\u001b[0m y_word \u001b[39m=\u001b[39m target_index_word[y_index]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Oh/Desktop/Machine_Learning/deep_learning/pet_projects/Attention_translator/attention_translator_part_1.ipynb#ch0000024?line=22'>23</a>\u001b[0m decoded_sentence \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m y_word\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36margmax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/deep_learning/lib/python3.9/site-packages/numpy/core/fromnumeric.py:1216\u001b[0m, in \u001b[0;36margmax\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m   1129\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m \u001b[39mReturns the indices of the maximum values along an axis.\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1213\u001b[0m \u001b[39m(2, 1, 4)\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m kwds \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mkeepdims\u001b[39m\u001b[39m'\u001b[39m: keepdims} \u001b[39mif\u001b[39;00m keepdims \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39m_NoValue \u001b[39melse\u001b[39;00m {}\n\u001b[0;32m-> 1216\u001b[0m \u001b[39mreturn\u001b[39;00m _wrapfunc(a, \u001b[39m'\u001b[39;49m\u001b[39margmax\u001b[39;49m\u001b[39m'\u001b[39;49m, axis\u001b[39m=\u001b[39;49maxis, out\u001b[39m=\u001b[39;49mout, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/deep_learning/lib/python3.9/site-packages/numpy/core/fromnumeric.py:54\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     52\u001b[0m bound \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(obj, method, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m     53\u001b[0m \u001b[39mif\u001b[39;00m bound \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 54\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m     56\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m     \u001b[39mreturn\u001b[39;00m bound(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/deep_learning/lib/python3.9/site-packages/numpy/core/fromnumeric.py:43\u001b[0m, in \u001b[0;36m_wrapit\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m     wrap \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(asarray(obj), method)(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m     44\u001b[0m \u001b[39mif\u001b[39;00m wrap:\n\u001b[1;32m     45\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(result, mu\u001b[39m.\u001b[39mndarray):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/deep_learning/lib/python3.9/site-packages/keras/engine/keras_tensor.py:254\u001b[0m, in \u001b[0;36mKerasTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\u001b[39mself\u001b[39m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 254\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    255\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mYou are passing \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, an intermediate Keras symbolic input/output, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    256\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mto a TF API that does not allow registering custom dispatchers, such \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    257\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mas `tf.cond`, `tf.function`, gradient tapes, or `tf.map_fn`. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    258\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mKeras Functional model construction only supports \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    259\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mTF API calls that *do* support dispatching, such as `tf.math.add` or \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    260\u001b[0m       \u001b[39m'\u001b[39m\u001b[39m`tf.reshape`. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    261\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mOther APIs cannot be called directly on symbolic Keras\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    262\u001b[0m       \u001b[39m'\u001b[39m\u001b[39minputs/outputs. You can work around \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    263\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mthis limitation by putting the operation in a custom Keras layer \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    264\u001b[0m       \u001b[39m'\u001b[39m\u001b[39m`call` and calling that layer \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    265\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mon this symbolic input/output.\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: You are passing KerasTensor(type_spec=TensorSpec(shape=(10160,), dtype=tf.float32, name=None), name='tf.__operators__.getitem_11/strided_slice:0', description=\"created by layer 'tf.__operators__.getitem_11'\"), an intermediate Keras symbolic input/output, to a TF API that does not allow registering custom dispatchers, such as `tf.cond`, `tf.function`, gradient tapes, or `tf.map_fn`. Keras Functional model construction only supports TF API calls that *do* support dispatching, such as `tf.math.add` or `tf.reshape`. Other APIs cannot be called directly on symbolic Kerasinputs/outputs. You can work around this limitation by putting the operation in a custom Keras layer `call` and calling that layer on this symbolic input/output."
     ]
    }
   ],
   "source": [
    "sentences = list(X_train.iloc[:10].values)\n",
    "\n",
    "translations = []\n",
    "for sentence in sentences:\n",
    "    seq = sentence_to_seq(sentence)\n",
    "    translation = decode_sequence(seq)\n",
    "    translations.append(translation)\n",
    "\n",
    "sentence_translation_pairs = zip (sentences, translations)\n",
    "for elem in sentence_translation_pairs:\n",
    "    print (elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase all characters\n",
    "df_en_de['english'] = df_en_de['english'].apply(lambda x: x.lower())\n",
    "df_en_de['german'] = df_en_de['german'].apply(lambda x: x.lower())\n",
    "\n",
    "# Remove quotes\n",
    "df_en_de['english'] = df_en_de['english'].apply(lambda x: re.sub(\"'\", '', x))\n",
    "df_en_de['german'] = df_en_de['german'].apply(lambda x: re.sub(\"'\", '', x))\n",
    "\n",
    "# Set of all special characters\n",
    "exclude = set(string.punctuation) \n",
    "\n",
    "# Remove all the special characters\n",
    "df_en_de['english'] = df_en_de['english'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "df_en_de['german']=df_en_de['german'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "\n",
    "# Add start and end tokens to target sequences\n",
    "df_en_de['english'] = df_en_de['english'].apply(lambda x : '<start> '+ x + ' <end>')\n",
    "df_en_de['german'] = df_en_de['german'].apply(lambda x : '<start> '+ x + ' <end>')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename dataframe for convenience\n",
    "pairs = df_en_de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199379\n",
      "19938\n"
     ]
    }
   ],
   "source": [
    "max_len = 10\n",
    "\n",
    "pairs = df_en_de\n",
    "pairs['english_length'] = pairs['english'].apply(lambda x: len(x.split(' ')))\n",
    "pairs['german_length'] = pairs['german'].apply(lambda x: len(x.split(' ')))\n",
    "\n",
    "pairs = pairs[pairs['english_length'] <= max_len]\n",
    "pairs = pairs[pairs['german_length'] <= max_len]\n",
    "print(len(pairs))\n",
    "pairs = pairs.sample(frac = 0.1)\n",
    "print(len(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>german</th>\n",
       "      <th>english_length</th>\n",
       "      <th>german_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78158</th>\n",
       "      <td>&lt;start&gt; two plus two makes four &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; zwei plus zwei ist vier &lt;end&gt;</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28780</th>\n",
       "      <td>&lt;start&gt; you cant fire me &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; sie können mir nicht kündigen &lt;end&gt;</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35875</th>\n",
       "      <td>&lt;start&gt; why dont you stop &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; warum hältst du nicht an &lt;end&gt;</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     english  \\\n",
       "78158  <start> two plus two makes four <end>   \n",
       "28780         <start> you cant fire me <end>   \n",
       "35875        <start> why dont you stop <end>   \n",
       "\n",
       "                                            german  english_length  \\\n",
       "78158        <start> zwei plus zwei ist vier <end>               7   \n",
       "28780  <start> sie können mir nicht kündigen <end>               6   \n",
       "35875       <start> warum hältst du nicht an <end>               6   \n",
       "\n",
       "       german_length  \n",
       "78158              7  \n",
       "28780              7  \n",
       "35875              7  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_text = list(pairs['english'])\n",
    "german_text = list(pairs['german'])\n",
    "both = list(map(list, zip(english_text, german_text)))\n",
    "cleaned_pairs = both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<start> two plus two makes four <end>',\n",
       "  '<start> zwei plus zwei ist vier <end>'],\n",
       " ['<start> you cant fire me <end>',\n",
       "  '<start> sie können mir nicht kündigen <end>'],\n",
       " ['<start> why dont you stop <end>', '<start> warum hältst du nicht an <end>'],\n",
       " ['<start> where did you get all this from <end>',\n",
       "  '<start> woher hast du das alles <end>'],\n",
       " ['<start> were you in boston last week <end>',\n",
       "  '<start> warst du letzte woche in boston <end>']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_pairs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class creates a word -> index mapping (e.g,. \"dad\" -> 5) and vice-versa \n",
    "# (e.g., 5 -> \"dad\") for each language,\n",
    "class LanguageIndex():\n",
    "    def __init__(self, lang):\n",
    "        self.lang = lang\n",
    "        self.word2idx = {}\n",
    "        self.idx2word = {}\n",
    "        self.vocab = set()\n",
    "\n",
    "        self.create_index()                 # Run the function when you initialise class\n",
    "                                            # So when you initialise the class, \n",
    "                                            # the variable has word2idx and idx2word dictionaries already\n",
    "\n",
    "\n",
    "    def create_index(self):\n",
    "        for phrase in self.lang:\n",
    "            self.vocab.update(phrase.split(' '))\n",
    "\n",
    "        self.vocab = sorted(self.vocab)\n",
    "\n",
    "        self.word2idx['<pad>'] = 0\n",
    "        for index, word in enumerate(self.vocab):\n",
    "            self.word2idx[word] = index + 1\n",
    "\n",
    "        for word, index in self.word2idx.items():\n",
    "            self.idx2word[index] = word\n",
    "\n",
    "# Function to calculate maximum length of the sequence\n",
    "def max_length(tensor):\n",
    "    return max(len(t) for t in tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(pairs, num_examples):\n",
    "\n",
    "    inp_lang = LanguageIndex(en for en, de in cleaned_pairs)\n",
    "    targ_lang = LanguageIndex(de for en, de in cleaned_pairs)\n",
    "\n",
    "    # English sentences\n",
    "    input_tensor = [[inp_lang.word2idx[s] for s in en.split(' ')] for en, de in cleaned_pairs]\n",
    "    # German sentences\n",
    "    target_tensor = [[targ_lang.word2idx[s] for s in de.split(' ')] for en, de in cleaned_pairs]\n",
    "\n",
    "    # Calculate max_length of input and output tensor\n",
    "    # Here, we'll set those to the longest sentence in the dataset\n",
    "    max_length_inp, max_length_tar = max_length(input_tensor), max_length(target_tensor)\n",
    "\n",
    "    # Padding the input and output tensor to the maximum length\n",
    "    # First argument of pad_sequences = list of sequences, where each sequence is a list of integers\n",
    "    # second argument = number of integers per sequence\n",
    "    # make sure to set \"padding\" = \"post\" to append zeros at end and not beginning\n",
    "    input_tensor = tf.keras.preprocessing.sequence.pad_sequences(input_tensor, \n",
    "                                                                    maxlen=max_length_inp,\n",
    "                                                                    padding='post')\n",
    "\n",
    "    target_tensor = tf.keras.preprocessing.sequence.pad_sequences(target_tensor, \n",
    "                                                                    maxlen=max_length_tar, \n",
    "                                                                    padding='post')\n",
    "\n",
    "    return input_tensor, target_tensor, inp_lang, targ_lang, max_length_inp, max_length_tar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the tensors\n",
    "input_tensor, target_tensor, inp_lang, targ_lang, max_length_inp, max_length_targ = load_dataset(cleaned_pairs, len(cleaned_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating training and validation sets using an 80-20 split\n",
    "# each training set is 2D numpy arary\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.1, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17944, 10), (17944, 10))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor_train.shape, target_tensor_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  62, 1758, 9037, 6570, 1658,   61,    0,    0,    0,    0],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor_train[0]\n",
    "target_tensor_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-30 08:26:07.286937: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Set the parameters of the model\n",
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "N_BATCH = BUFFER_SIZE//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_lang.word2idx)\n",
    "vocab_tar_size = len(targ_lang.word2idx)\n",
    "\n",
    "# Create batch generator to be used by modle to load data in batches\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (280, 2, 64, 10)\n"
     ]
    }
   ],
   "source": [
    "train_np = np.stack(list(dataset))\n",
    "print(type(train_np), train_np.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gru(units):\n",
    "  \n",
    "    return tf.keras.layers.GRU(units, \n",
    "                                return_sequences=True, \n",
    "                                return_state=True, \n",
    "                                recurrent_activation='sigmoid',             # recurrent_activation refers to the \"update gate\"\n",
    "                                recurrent_initializer='glorot_uniform')\n",
    "\n",
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = gru(self.enc_units)\n",
    "        \n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state = hidden)        \n",
    "        return output, state\n",
    "    \n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = gru(self.dec_units)\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "        # used for attention\n",
    "        self.W1 = tf.keras.layers.Dense(self.dec_units)\n",
    "        self.W2 = tf.keras.layers.Dense(self.dec_units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, x, hidden, enc_output):\n",
    "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "        \n",
    "        # hidden shape == (batch_size, hidden size)\n",
    "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # we are doing this to perform addition to calculate the score\n",
    "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
    "        \n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying tanh(FC(EO) + FC(H)) to self.V\n",
    "        # this is the step 1 described in the blog to compute scores s1, s2, ...\n",
    "        score = self.V(tf.nn.tanh(self.W1(enc_output) + self.W2(hidden_with_time_axis)))\n",
    "        \n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        # this is the step 2 described in the blog to compute attention weights e1, e2, ...\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        \n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        # this is the step 3 described in the blog to compute the context_vector = e1*h1 + e2*h2 + ...\n",
    "        context_vector = attention_weights * enc_output\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        \n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        # this is the step 4 described in the blog to concatenate the context vector with the output of the previous time step\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        \n",
    "        # passing the concatenated vector to the GRU\n",
    "        output, state = self.gru(x)\n",
    "        \n",
    "        # output shape == (batch_size * 1, hidden_size)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        \n",
    "        # output shape == (batch_size * 1, vocab)\n",
    "        # this is the step 5 in the blog, to compute the next output word in the sequence\n",
    "        x = self.fc(output)\n",
    "        \n",
    "        # return current output, current state and the attention weights\n",
    "        return x, state, attention_weights\n",
    "        \n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.dec_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create objects of Class Encoder and Class Decoder\n",
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('deep_learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "62f0de500e91648e2f1c8ecd59ca95f97588cc062e27f09a44618e0428f97b74"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
