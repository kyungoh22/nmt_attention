{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- data source: http://www.manythings.org/anki/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This file also works. Still no pre-trained embeddings. \n",
    "- Used functions for code blocks. But that didn't really make things much neater. \n",
    "- In part 5, incorporate pre-trained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, RNN, Multiply\n",
    "from tensorflow.keras.layers import RepeatVector, Dense, Activation, Lambda, Embedding, Reshape\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string \n",
    "import regex as re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import io\n",
    "import spacy\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# from tensorflow.python.framework.ops import disable_eager_execution\n",
    "# disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')\n",
    "\n",
    "# df_en_de = pd.read_table('/content/gdrive/MyDrive/deu-eng/deu.txt', names=['eng', 'deu', 'attr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_en_de = pd.read_table('deu-eng/deu.txt', names=['eng', 'deu', 'attr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_en_de = df_en_de.drop('attr',axis = 1).rename(columns = {'eng':'english', 'deu':'german'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase all characters\n",
    "df_en_de['english'] = df_en_de['english'].apply(lambda x: x.lower())\n",
    "df_en_de['german'] = df_en_de['german'].apply(lambda x: x.lower())\n",
    "\n",
    "# Remove quotes\n",
    "df_en_de['english'] = df_en_de['english'].apply(lambda x: re.sub(\"'\", '', x))\n",
    "df_en_de['german'] = df_en_de['german'].apply(lambda x: re.sub(\"'\", '', x))\n",
    "\n",
    "# Set of all special characters\n",
    "exclude = set(string.punctuation) \n",
    "\n",
    "# Remove all the special characters\n",
    "df_en_de['english'] = df_en_de['english'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "df_en_de['german']=df_en_de['german'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "\n",
    "# Add start and end tokens to target sequences\n",
    "df_en_de['german'] = df_en_de['german'].apply(lambda x : 'START_ '+ x + ' _END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209317\n",
      "20932\n"
     ]
    }
   ],
   "source": [
    "max_len = 10\n",
    "\n",
    "pairs = df_en_de\n",
    "pairs['english_length'] = pairs['english'].apply(lambda x: len(x.split(' ')))\n",
    "pairs['german_length'] = pairs['german'].apply(lambda x: len(x.split(' ')))\n",
    "\n",
    "pairs = pairs[pairs['english_length'] <= max_len]\n",
    "pairs = pairs[pairs['german_length'] <= max_len]\n",
    "print(len(pairs))\n",
    "pairs = pairs.sample(frac = 0.1)\n",
    "print(len(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary of English\n",
    "all_en_words=set()\n",
    "for eng in pairs['english']:\n",
    "    for word in eng.split():\n",
    "        if word not in all_en_words:\n",
    "            all_en_words.add(word)\n",
    "\n",
    "# Vocabulary of German \n",
    "all_de_words=set()\n",
    "for de in pairs['german']:\n",
    "    for word in de.split():\n",
    "        if word not in all_de_words:\n",
    "            all_de_words.add(word)\n",
    "\n",
    "# Max Length of source sequence\n",
    "length_list=[]\n",
    "for l in pairs['english']:\n",
    "    length_list.append(len(l.split(' ')))\n",
    "max_length_src = np.max(length_list)\n",
    "\n",
    "# Max Length of target sequence\n",
    "length_list=[]\n",
    "for l in pairs['german']:\n",
    "    length_list.append(len(l.split(' ')))\n",
    "max_length_tar = np.max(length_list)\n",
    "\n",
    "\n",
    "input_words = sorted(list(all_en_words))\n",
    "target_words = sorted(list(all_de_words))\n",
    "\n",
    "# Calculate Vocab size for both source and target\n",
    "# Add 1 for zero padding\n",
    "num_encoder_tokens = len(all_en_words) + 1\n",
    "num_decoder_tokens = len(all_de_words) + 1\n",
    "\n",
    "# Create word to token dictionary for both source and target\n",
    "#input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
    "#target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])\n",
    "input_word_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
    "target_word_index = dict([(word, i+1) for i, word in enumerate(target_words)])\n",
    "\n",
    "# Create token to word dictionary for both source and target\n",
    "# reverse_input_token_index = dict((i, word) for word, i in input_token_index.items())\n",
    "# reverse_target_token_index = dict((i, word) for word, i in target_token_index.items())\n",
    "input_index_word = dict((i, word) for word, i in input_word_index.items())\n",
    "target_index_word = dict((i, word) for word, i in target_word_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = pairs['english'], pairs['german']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(X = X_train, y = y_train, batch_size = 128):\n",
    "    ''' Generate a batch of data '''\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):          # j = batch number\n",
    "            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32') # (m, max_len)\n",
    "            \n",
    "            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32') # (m, max_len)\n",
    "\n",
    "            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')    # (m, max_len, num_decoder_tokens)\n",
    "            \n",
    "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
    "                for t, word in enumerate(input_text.split()):\n",
    "                    encoder_input_data[i, t] = input_word_index[word] # encoder input seq\n",
    "                for t, word in enumerate(target_text.split()):\n",
    "                    if t<len(target_text.split())-1:\n",
    "                        decoder_input_data[i, t] = target_word_index[word] # decoder input seq\n",
    "                    if t>0:\n",
    "                        # decoder target sequence (one hot encoded)\n",
    "                        # does not include the START_ token\n",
    "                        # Offset by one timestep\n",
    "                        decoder_target_data[i, t - 1, target_word_index[word]] = 1. \n",
    "                        \"\"\" This should be target_token_index[word] - 1\"\"\"\n",
    "            # decoder_target_data = np.transpose(decoder_target_data, axes = [1, 0, 2])\n",
    "            # decoder_target_data = list(decoder_target_data)\n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10153"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_decoder_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- global variables for one_step_attention:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tx = max_len\n",
    "Ty = max_len\n",
    "repeator = RepeatVector(Tx)\n",
    "concatenator = Concatenate(axis = -1)\n",
    "densor1 = Dense(10, activation = 'tanh')\n",
    "densor2 = Dense (1, activation = 'relu')\n",
    "dotor = Dot(axes = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_step_attention (h, s_prev):\n",
    "\n",
    "    # calculate the Context vector for one time-step of decoder\n",
    "\n",
    "    # h = (m, Tx, n_h)\n",
    "    # s_prev = (m, n_s)\n",
    "    # returns: context – we will then use [context; y_prev] as input of Decoder\n",
    "\n",
    "    s_prev = repeator(s_prev)                   # (m, Tx, n_s)\n",
    "    concat = concatenator([h, s_prev])          # (m, Tx, n_h + n_s)\n",
    "    e = densor1 (concat)                        # (m, Tx, 10)\n",
    "    energies = densor2 (e)                      # (m, Tx, 1)\n",
    "    alphas = tf.nn.softmax(energies, axis = 1)  # (m, Tx, 1)\n",
    "    context = dotor([alphas, h])                # alphas = (m, Tx, 1)\n",
    "                                                # h = (m, Tx, n_h)\n",
    "                                                # (m, 1, n_h)\n",
    "    return context                              # (m, 1, n_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_emb_dim = 300\n",
    "y_emb_dim = 300\n",
    "\n",
    "n_h = 200\n",
    "n_s = 200\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- global variables for pre-attention LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_inputs = Input(shape = (Tx,))                         # (None, Tx) = (m, Tx)\n",
    "x_emb_layer = Embedding(num_encoder_tokens, x_emb_dim, mask_zero = True)  \n",
    "x_emb = x_emb_layer(x_inputs)                         # (None, Tx, x_emb_dim) = (m, Tx, x_emb_dim)\n",
    "\n",
    "enc_lstm_layer = LSTM(n_h, dropout = 0.3, return_sequences=True, return_state = True)\n",
    "h_enc, s_enc, c_enc = enc_lstm_layer(x_emb)                             # h_enc = (None, Tx, n_h) = (m, Tx, n_h)\n",
    "                                                                        # s_enc = (None, n_h) = (m, n_h)\n",
    "                                                                        # c_enc = (None, n_h) = (m, n_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- global variables for post-attention LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_inputs = Input(shape = (Ty,))                         # (None, Ty) = (m, Ty)\n",
    "y_emb_layer = Embedding (num_decoder_tokens, y_emb_dim, mask_zero = True)\n",
    "y_emb = y_emb_layer(y_inputs)                         # (None, Ty, y_emb_dim) = (m, Ty, y_emb_dim)\n",
    "\n",
    "\n",
    "dec_lstm_layer = LSTM(n_s, dropout = 0.3, return_state = True)\n",
    "output_layer = Dense(num_decoder_tokens, activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_model():\n",
    "\n",
    "    # s<0> and c<0> for decoder = s<Ty> and c<Ty> for encoder\n",
    "    s_dec = s_enc\n",
    "    c_dec = c_enc                                                              \n",
    "\n",
    "    outputs = []\n",
    "    for t in range(Ty):\n",
    "        context = one_step_attention(h_enc, s_dec)                                            # context = (m, 1, n_h)\n",
    "        concat = Concatenate(axis = -1)([context, tf.expand_dims(y_emb[:,t,:],1)])            # concat = (m, 1, n_h + y_emb_dim)\n",
    "        \n",
    "        # update decoder LSTM hidden state (s) and cell state (c)\n",
    "        _, s_dec, c_dec = dec_lstm_layer (initial_state = [s_dec, c_dec], inputs = concat)        # s = (None, Ty, n_s)\n",
    "        \n",
    "        # pass decoder LSTM hidden state (s) through output layer to get y prediction\n",
    "        out = output_layer(s_dec)                                                                   # out = (m, num_decoder_tokens)\n",
    "        outputs.append(out)\n",
    "                                                                \n",
    "    outputs = tf.stack(outputs, axis = 1)\n",
    "    training_model = Model(inputs = [x_inputs, y_inputs], outputs = outputs)\n",
    "\n",
    "    return training_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_model = training_model()\n",
    "training_model.compile(optimizer= 'Adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "train_samples = len(X_train) # Total Training samples\n",
    "val_samples = len(X_test) # total validation samples\n",
    "batch_size = 128\n",
    "epochs = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "130/130 [==============================] - 64s 362ms/step - loss: 4.1316 - acc: 0.1156 - val_loss: 3.7891 - val_acc: 0.1225\n",
      "Epoch 2/5\n",
      "130/130 [==============================] - 40s 305ms/step - loss: 3.6214 - acc: 0.1252 - val_loss: 3.7003 - val_acc: 0.1283\n",
      "Epoch 3/5\n",
      "130/130 [==============================] - 38s 294ms/step - loss: 3.4759 - acc: 0.1363 - val_loss: 3.5211 - val_acc: 0.1422\n",
      "Epoch 4/5\n",
      "130/130 [==============================] - 38s 294ms/step - loss: 3.2668 - acc: 0.1510 - val_loss: 3.3682 - val_acc: 0.1568\n",
      "Epoch 5/5\n",
      "130/130 [==============================] - 38s 295ms/step - loss: 3.0854 - acc: 0.1663 - val_loss: 3.2396 - val_acc: 0.1716\n"
     ]
    }
   ],
   "source": [
    "history = training_model.fit(generate_batch(), \n",
    "                    steps_per_epoch=train_samples//batch_size, \n",
    "                    epochs = 5,\n",
    "                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n",
    "                    validation_steps = val_samples // batch_size, \n",
    "                    verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "130/130 [==============================] - 40s 309ms/step - loss: 2.9317 - acc: 0.1861 - val_loss: 3.1203 - val_acc: 0.1958\n",
      "Epoch 2/10\n",
      "130/130 [==============================] - 39s 302ms/step - loss: 2.7684 - acc: 0.2089 - val_loss: 3.0117 - val_acc: 0.2121\n",
      "Epoch 3/10\n",
      "130/130 [==============================] - 42s 322ms/step - loss: 2.6249 - acc: 0.2245 - val_loss: 2.9209 - val_acc: 0.2220\n",
      "Epoch 4/10\n",
      "130/130 [==============================] - 39s 298ms/step - loss: 2.4961 - acc: 0.2370 - val_loss: 2.8539 - val_acc: 0.2307\n",
      "Epoch 5/10\n",
      "130/130 [==============================] - 44s 337ms/step - loss: 2.3825 - acc: 0.2491 - val_loss: 2.7907 - val_acc: 0.2380\n",
      "Epoch 6/10\n",
      "130/130 [==============================] - 38s 291ms/step - loss: 2.2723 - acc: 0.2599 - val_loss: 2.7265 - val_acc: 0.2468\n",
      "Epoch 7/10\n",
      "130/130 [==============================] - 39s 298ms/step - loss: 2.1669 - acc: 0.2713 - val_loss: 2.6733 - val_acc: 0.2547\n",
      "Epoch 8/10\n",
      "130/130 [==============================] - 38s 296ms/step - loss: 2.0638 - acc: 0.2827 - val_loss: 2.6195 - val_acc: 0.2604\n",
      "Epoch 9/10\n",
      "130/130 [==============================] - 38s 293ms/step - loss: 1.9671 - acc: 0.2929 - val_loss: 2.5764 - val_acc: 0.2658\n",
      "Epoch 10/10\n",
      "130/130 [==============================] - 38s 291ms/step - loss: 1.8732 - acc: 0.3027 - val_loss: 2.5411 - val_acc: 0.2695\n"
     ]
    }
   ],
   "source": [
    "history2 = training_model.fit(generate_batch(), \n",
    "                    steps_per_epoch=train_samples//batch_size, \n",
    "                    epochs = 10,\n",
    "                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n",
    "                    validation_steps = val_samples // batch_size, \n",
    "                    verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_model():\n",
    "    # x_inputs defined above as Input\n",
    "    # h_enc, s_enc, c_enc also defined above\n",
    "    encoder_model = Model(inputs = x_inputs, outputs = [h_enc, s_enc, c_enc])\n",
    "    return encoder_model\n",
    "\n",
    "def decoder_model():\n",
    "    # The below three decoder inputs will come from encoder_model.predict()\n",
    "    decoder_input_h = Input(shape = (Tx, n_h))               # (None, Tx, n_h) \n",
    "    decoder_input_s = Input(shape=(n_s, ))                    # (None, n_s) \n",
    "    decoder_input_c = Input(shape = (n_s,))                   # (None, n_s) \n",
    "\n",
    "    # y_emb_2 will be our y_pred at t-1\n",
    "    y_inp_2 = Input(shape = (None,))                        # (None, None) = (m, Ty)\n",
    "    y_emb_2 = y_emb_layer(y_inp_2)                          # (None, None, y_emb_dim) = (m, Ty, y_emb_dim)\n",
    "\n",
    "    # Use decoder_input_s and decoder_input_h to compute context vector\n",
    "    context = one_step_attention(decoder_input_h, decoder_input_s)    # (m, 1, n_h)\n",
    "\n",
    "    # concatenate context with y_emb_2\n",
    "    concat2 = Concatenate(axis = -1)([context, tf.expand_dims(y_emb_2[:,-1,:],1)])                       \n",
    "                                                            # concat2 = (None, 1, n_h + y_emb_dim)\n",
    "\n",
    "    # Feed concat2 as input; decoder_input_s and decoder_input_c as initial state\n",
    "    _, decoder_output_s, decoder_output_c = dec_lstm_layer (\n",
    "                                                            initial_state = [decoder_input_s, decoder_input_c], \n",
    "                                                            inputs = concat2\n",
    "                                                            )     \n",
    "                                                # decoder_output_s = (None, n_s) \n",
    "                                                # decoder_output_c = (None, n_s) \n",
    "\n",
    "    #decoder_output_s = tf.expand_dims(decoder_output_s, 1)      # decoder_output_s = (None, 1, n_s)\n",
    "    #decoder_output_c = tf.expand_dims(decoder_output_c, 1)      # decoder_output_c = (None, 1, n_s)\n",
    "    decoder_output_y = output_layer(tf.expand_dims(decoder_output_s,1))           # (None, 1, num_decoder_tokens)\n",
    "\n",
    "    decoder_model = Model(inputs = [decoder_input_h, decoder_input_s, decoder_input_c, y_inp_2],\n",
    "                            outputs = [decoder_output_y, decoder_output_s, decoder_output_c])\n",
    "    return decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = encoder_model()\n",
    "decoder_model = decoder_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_sequence):\n",
    "\n",
    "    # input_sequence = (1, max_len)\n",
    "    \n",
    "    # get hidden states + final hidden state + final cell state from encoder \n",
    "    h_enc_pred, s_enc_pred, c_enc_pred = encoder_model.predict(input_sequence)\n",
    "    \n",
    "    # define y_pred at time 0    \n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0,0] = target_word_index['START_']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "\n",
    "    # initialise hidden state and cell state input for decoder\n",
    "    decoder_s_pred = s_enc_pred                         # (None, n_h) = (m, n_h)\n",
    "    decoder_c_pred = c_enc_pred                         # (None, n_h) = (m, n_h)\n",
    "    \n",
    "    while not stop_condition:\n",
    "        decoder_y_pred, decoder_s_pred, decoder_c_pred = decoder_model.predict([h_enc_pred, decoder_s_pred, decoder_c_pred, target_seq])  \n",
    "        y_index = np.argmax(decoder_y_pred[0,-1,:])\n",
    "        y_word = target_index_word[y_index]\n",
    "        decoded_sentence += ' ' + y_word\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (y_word == '_END' or\n",
    "           len(decoded_sentence.split()) > max_len):\n",
    "            stop_condition = True\n",
    "        \n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = y_index\n",
    "        \n",
    "    return decoded_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_seq(sentence):\n",
    "    \"\"\"\n",
    "    sentence = string\n",
    "    \"\"\"\n",
    "    \n",
    "    encoder_input_data = np.zeros((1, max_len))     # (1, max_len)\n",
    "    \n",
    "    sentence = sentence.lower().split()\n",
    "    #print(sentence)\n",
    "    for j, word in enumerate(sentence):\n",
    "        encoder_input_data[0,j] = input_word_index[word]        # (1, max_len)\n",
    "    # print(encoder_input_data.shape)\n",
    "    return encoder_input_data                           # (1, max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('most boys know his name', ' die polizei hat sich an den tod _END')\n",
      "('he knows how to play poker', ' er hat die ganze nacht _END')\n",
      "('its just the right size', ' es ist das haus _END')\n",
      "('could i have some more coffee', ' kann ich eine arbeit ein bisschen _END')\n",
      "('tom had a lump on his head', ' tom wurde im glas auf dem _END')\n",
      "('nobody cares what you think', ' niemand weiß dass du das getan _END')\n",
      "('tom is flustered', ' tom ist _END')\n",
      "('she went into her room to change her dress', ' sie hat die brief und des paar minuten _END')\n",
      "('im not one of your students', ' ich bin nicht ein sehr alt _END')\n",
      "('have you tried it yet', ' hast du das schon gemacht _END')\n"
     ]
    }
   ],
   "source": [
    "sentences = list(X_train.iloc[:10].values)          # list of sentences\n",
    "\n",
    "translations = []\n",
    "for sentence in sentences:\n",
    "    seq = sentence_to_seq(sentence)             # seq = (1, max_len)\n",
    "    #print(seq, seq.shape)\n",
    "    translation = decode_sequence(seq)\n",
    "    translations.append(translation)\n",
    "\n",
    "sentence_translation_pairs = zip (sentences, translations)\n",
    "for elem in sentence_translation_pairs:\n",
    "    print (elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('deep_learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "62f0de500e91648e2f1c8ecd59ca95f97588cc062e27f09a44618e0428f97b74"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
