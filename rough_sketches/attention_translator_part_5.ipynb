{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- data source: http://www.manythings.org/anki/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This file also works. Still no pre-trained embeddings. \n",
    "- Used functions for code blocks. But that didn't really make things much neater. \n",
    "- Bidirectional LSTM for encoder\n",
    "- In part 6, incorporate pre-trained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, RNN, Multiply\n",
    "from tensorflow.keras.layers import RepeatVector, Dense, Activation, Lambda, Embedding, Reshape\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string \n",
    "import regex as re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import io\n",
    "import spacy\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# from tensorflow.python.framework.ops import disable_eager_execution\n",
    "# disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')\n",
    "\n",
    "# df_en_de = pd.read_table('/content/gdrive/MyDrive/deu-eng/deu.txt', names=['eng', 'deu', 'attr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_en_de = pd.read_table('deu-eng/deu.txt', names=['eng', 'deu', 'attr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_en_de = df_en_de.drop('attr',axis = 1).rename(columns = {'eng':'english', 'deu':'german'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase all characters\n",
    "df_en_de['english'] = df_en_de['english'].apply(lambda x: x.lower())\n",
    "df_en_de['german'] = df_en_de['german'].apply(lambda x: x.lower())\n",
    "\n",
    "# Remove quotes\n",
    "df_en_de['english'] = df_en_de['english'].apply(lambda x: re.sub(\"'\", '', x))\n",
    "df_en_de['german'] = df_en_de['german'].apply(lambda x: re.sub(\"'\", '', x))\n",
    "\n",
    "# Set of all special characters\n",
    "exclude = set(string.punctuation) \n",
    "\n",
    "# Remove all the special characters\n",
    "df_en_de['english'] = df_en_de['english'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "df_en_de['german']=df_en_de['german'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "\n",
    "# Add start and end tokens to target sequences\n",
    "df_en_de['german'] = df_en_de['german'].apply(lambda x : 'START_ '+ x + ' _END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209317\n",
      "20932\n"
     ]
    }
   ],
   "source": [
    "max_len = 10\n",
    "\n",
    "pairs = df_en_de\n",
    "pairs['english_length'] = pairs['english'].apply(lambda x: len(x.split(' ')))\n",
    "pairs['german_length'] = pairs['german'].apply(lambda x: len(x.split(' ')))\n",
    "\n",
    "pairs = pairs[pairs['english_length'] <= max_len]\n",
    "pairs = pairs[pairs['german_length'] <= max_len]\n",
    "print(len(pairs))\n",
    "pairs = pairs.sample(frac = 0.1)\n",
    "print(len(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary of English\n",
    "all_en_words=set()\n",
    "for eng in pairs['english']:\n",
    "    for word in eng.split():\n",
    "        if word not in all_en_words:\n",
    "            all_en_words.add(word)\n",
    "\n",
    "# Vocabulary of German \n",
    "all_de_words=set()\n",
    "for de in pairs['german']:\n",
    "    for word in de.split():\n",
    "        if word not in all_de_words:\n",
    "            all_de_words.add(word)\n",
    "\n",
    "# Max Length of source sequence\n",
    "length_list=[]\n",
    "for l in pairs['english']:\n",
    "    length_list.append(len(l.split(' ')))\n",
    "max_length_src = np.max(length_list)\n",
    "\n",
    "# Max Length of target sequence\n",
    "length_list=[]\n",
    "for l in pairs['german']:\n",
    "    length_list.append(len(l.split(' ')))\n",
    "max_length_tar = np.max(length_list)\n",
    "\n",
    "\n",
    "input_words = sorted(list(all_en_words))\n",
    "target_words = sorted(list(all_de_words))\n",
    "\n",
    "# Calculate Vocab size for both source and target\n",
    "# Add 1 for zero padding\n",
    "num_encoder_tokens = len(all_en_words) + 1\n",
    "num_decoder_tokens = len(all_de_words) + 1\n",
    "\n",
    "# Create word to token dictionary for both source and target\n",
    "#input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
    "#target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])\n",
    "input_word_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
    "target_word_index = dict([(word, i+1) for i, word in enumerate(target_words)])\n",
    "\n",
    "# Create token to word dictionary for both source and target\n",
    "# reverse_input_token_index = dict((i, word) for word, i in input_token_index.items())\n",
    "# reverse_target_token_index = dict((i, word) for word, i in target_token_index.items())\n",
    "input_index_word = dict((i, word) for word, i in input_word_index.items())\n",
    "target_index_word = dict((i, word) for word, i in target_word_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = pairs['english'], pairs['german']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(X = X_train, y = y_train, batch_size = 128):\n",
    "    ''' Generate a batch of data '''\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):          # j = batch number\n",
    "            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32') # (m, max_len)\n",
    "            \n",
    "            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32') # (m, max_len)\n",
    "\n",
    "            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')    # (m, max_len, num_decoder_tokens)\n",
    "            \n",
    "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
    "                for t, word in enumerate(input_text.split()):\n",
    "                    encoder_input_data[i, t] = input_word_index[word] # encoder input seq\n",
    "                for t, word in enumerate(target_text.split()):\n",
    "                    if t<len(target_text.split())-1:\n",
    "                        decoder_input_data[i, t] = target_word_index[word] # decoder input seq\n",
    "                    if t>0:\n",
    "                        # decoder target sequence (one hot encoded)\n",
    "                        # does not include the START_ token\n",
    "                        # Offset by one timestep\n",
    "                        decoder_target_data[i, t - 1, target_word_index[word]] = 1. \n",
    "                        \"\"\" This should be target_token_index[word] - 1\"\"\"\n",
    "            # decoder_target_data = np.transpose(decoder_target_data, axes = [1, 0, 2])\n",
    "            # decoder_target_data = list(decoder_target_data)\n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10258"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_decoder_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- global variables for one_step_attention:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tx = max_len\n",
    "Ty = max_len\n",
    "repeator = RepeatVector(Tx)\n",
    "concatenator = Concatenate(axis = -1)\n",
    "densor1 = Dense(10, activation = 'tanh')\n",
    "densor2 = Dense (1, activation = 'relu')\n",
    "dotor = Dot(axes = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_step_attention (h, s_prev):\n",
    "\n",
    "    # calculate the Context vector for one time-step of decoder\n",
    "\n",
    "    # h = (m, Tx, n_h)\n",
    "    # s_prev = (m, n_s)\n",
    "    # returns: context – we will then use [context; y_prev] as input of Decoder\n",
    "\n",
    "    s_prev = repeator(s_prev)                   # (m, Tx, n_s)\n",
    "    concat = concatenator([h, s_prev])          # (m, Tx, n_h + n_s)\n",
    "    e = densor1 (concat)                        # (m, Tx, 10)\n",
    "    energies = densor2 (e)                      # (m, Tx, 1)\n",
    "    alphas = tf.nn.softmax(energies, axis = 1)  # (m, Tx, 1)\n",
    "    context = dotor([alphas, h])                # alphas = (m, Tx, 1)\n",
    "                                                # h = (m, Tx, n_h)\n",
    "                                                # (m, 1, n_h)\n",
    "    return context                              # (m, 1, n_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_emb_dim = 300\n",
    "y_emb_dim = 300\n",
    "\n",
    "n_h = 200\n",
    "n_s = 200\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- global variables for pre-attention LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_inputs = Input(shape = (Tx,))                         # (None, Tx) = (m, Tx)\n",
    "x_emb_layer = Embedding(num_encoder_tokens, x_emb_dim, mask_zero = True)  \n",
    "x_emb = x_emb_layer(x_inputs)                         # (None, Tx, x_emb_dim) = (m, Tx, x_emb_dim)\n",
    "\n",
    "# Use bidirectional LSTM\n",
    "enc_lstm_layer = Bidirectional(LSTM(n_h, dropout = 0.3, recurrent_dropout = 0.3, return_sequences=True, return_state = True))\n",
    "h_enc, s_enc, c_enc, _, _ = enc_lstm_layer(x_emb)                             # h_enc = (None, Tx, n_h) = (m, Tx, 2*n_h)\n",
    "                                                                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- global variables for post-attention LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_inputs = Input(shape = (Ty,))                         # (None, Ty) = (m, Ty)\n",
    "y_emb_layer = Embedding (num_decoder_tokens, y_emb_dim, mask_zero = True)\n",
    "y_emb = y_emb_layer(y_inputs)                         # (None, Ty, y_emb_dim) = (m, Ty, y_emb_dim)\n",
    "\n",
    "\n",
    "dec_lstm_layer = LSTM(n_s, dropout = 0.3, recurrent_dropout = 0.3, return_state = True)\n",
    "output_layer = Dense(num_decoder_tokens, activation='softmax')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(y_inputs.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_model():\n",
    "\n",
    "    # s<0> and c<0> for decoder = s<Ty> and c<Ty> for encoder\n",
    "                                                                 \n",
    "    s_dec = s_enc\n",
    "    c_dec = c_enc\n",
    "    \n",
    "    outputs = []\n",
    "    for t in range(Ty):\n",
    "        context = one_step_attention(h_enc, s_dec)                                            # context = (m, 1, n_h)\n",
    "        concat = Concatenate(axis = -1)([context, tf.expand_dims(y_emb[:,t,:],1)])            # concat = (m, 1, n_h + y_emb_dim)\n",
    "        \n",
    "        # update decoder LSTM hidden state (s) and cell state (c)\n",
    "        _, s_dec, c_dec = dec_lstm_layer (initial_state = [s_dec, c_dec], inputs = concat)        # s = (None, Ty, n_s)\n",
    "        \n",
    "        # pass decoder LSTM hidden state (s) through output layer to get y prediction\n",
    "        out = output_layer(s_dec)                                                                   # out = (m, num_decoder_tokens)\n",
    "        outputs.append(out)\n",
    "                                                                \n",
    "    outputs = tf.stack(outputs, axis = 1)\n",
    "    training_model = Model(inputs = [x_inputs, y_inputs], outputs = outputs)\n",
    "\n",
    "    return training_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_model = training_model()\n",
    "training_model.compile(optimizer= 'Adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "train_samples = len(X_train) # Total Training samples\n",
    "val_samples = len(X_test) # total validation samples\n",
    "batch_size = 128\n",
    "epochs = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "130/130 [==============================] - 68s 350ms/step - loss: 4.1713 - acc: 0.1149 - val_loss: 3.7617 - val_acc: 0.1229\n",
      "Epoch 2/5\n",
      "130/130 [==============================] - 42s 324ms/step - loss: 3.6530 - acc: 0.1244 - val_loss: 3.6291 - val_acc: 0.1316\n",
      "Epoch 3/5\n",
      "130/130 [==============================] - 43s 327ms/step - loss: 3.4597 - acc: 0.1416 - val_loss: 3.4686 - val_acc: 0.1542\n",
      "Epoch 4/5\n",
      "130/130 [==============================] - 42s 325ms/step - loss: 3.2604 - acc: 0.1653 - val_loss: 3.2953 - val_acc: 0.1738\n",
      "Epoch 5/5\n",
      "130/130 [==============================] - 44s 336ms/step - loss: 3.0535 - acc: 0.1849 - val_loss: 3.1358 - val_acc: 0.1933\n"
     ]
    }
   ],
   "source": [
    "history = training_model.fit(generate_batch(), \n",
    "                    steps_per_epoch=train_samples//batch_size, \n",
    "                    epochs = 5,\n",
    "                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n",
    "                    validation_steps = val_samples // batch_size, \n",
    "                    verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "130/130 [==============================] - 41s 312ms/step - loss: 2.8784 - acc: 0.2040 - val_loss: 3.0066 - val_acc: 0.2073\n",
      "Epoch 2/10\n",
      "130/130 [==============================] - 41s 313ms/step - loss: 2.7094 - acc: 0.2190 - val_loss: 2.8964 - val_acc: 0.2186\n",
      "Epoch 3/10\n",
      "130/130 [==============================] - 41s 315ms/step - loss: 2.5601 - acc: 0.2331 - val_loss: 2.8040 - val_acc: 0.2301\n",
      "Epoch 4/10\n",
      "130/130 [==============================] - 41s 313ms/step - loss: 2.4246 - acc: 0.2469 - val_loss: 2.7179 - val_acc: 0.2409\n",
      "Epoch 5/10\n",
      "130/130 [==============================] - 41s 314ms/step - loss: 2.2946 - acc: 0.2609 - val_loss: 2.6456 - val_acc: 0.2515\n",
      "Epoch 6/10\n",
      "130/130 [==============================] - 43s 329ms/step - loss: 2.1744 - acc: 0.2742 - val_loss: 2.5834 - val_acc: 0.2593\n",
      "Epoch 7/10\n",
      "130/130 [==============================] - 47s 364ms/step - loss: 2.0574 - acc: 0.2877 - val_loss: 2.5259 - val_acc: 0.2675\n",
      "Epoch 8/10\n",
      "130/130 [==============================] - 44s 338ms/step - loss: 1.9478 - acc: 0.2995 - val_loss: 2.4684 - val_acc: 0.2760\n",
      "Epoch 9/10\n",
      "130/130 [==============================] - 45s 348ms/step - loss: 1.8477 - acc: 0.3110 - val_loss: 2.4200 - val_acc: 0.2826\n",
      "Epoch 10/10\n",
      "130/130 [==============================] - 42s 322ms/step - loss: 1.7511 - acc: 0.3220 - val_loss: 2.3817 - val_acc: 0.2887\n"
     ]
    }
   ],
   "source": [
    "history2 = training_model.fit(generate_batch(), \n",
    "                    steps_per_epoch=train_samples//batch_size, \n",
    "                    epochs = 10,\n",
    "                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n",
    "                    validation_steps = val_samples // batch_size, \n",
    "                    verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "130/130 [==============================] - 42s 319ms/step - loss: 1.6588 - acc: 0.3332 - val_loss: 2.3520 - val_acc: 0.2935\n",
      "Epoch 2/10\n",
      "130/130 [==============================] - 41s 315ms/step - loss: 1.5674 - acc: 0.3434 - val_loss: 2.3286 - val_acc: 0.2965\n",
      "Epoch 3/10\n",
      "130/130 [==============================] - 41s 317ms/step - loss: 1.4857 - acc: 0.3539 - val_loss: 2.2861 - val_acc: 0.3035\n",
      "Epoch 4/10\n",
      "130/130 [==============================] - 41s 317ms/step - loss: 1.4070 - acc: 0.3646 - val_loss: 2.2657 - val_acc: 0.3076\n",
      "Epoch 5/10\n",
      "130/130 [==============================] - 41s 316ms/step - loss: 1.3320 - acc: 0.3754 - val_loss: 2.2454 - val_acc: 0.3115\n",
      "Epoch 6/10\n",
      "130/130 [==============================] - 41s 319ms/step - loss: 1.2578 - acc: 0.3871 - val_loss: 2.2239 - val_acc: 0.3150\n",
      "Epoch 7/10\n",
      "130/130 [==============================] - 41s 313ms/step - loss: 1.1868 - acc: 0.3988 - val_loss: 2.2097 - val_acc: 0.3177\n",
      "Epoch 8/10\n",
      "130/130 [==============================] - 41s 316ms/step - loss: 1.1226 - acc: 0.4114 - val_loss: 2.2102 - val_acc: 0.3173\n",
      "Epoch 9/10\n",
      "130/130 [==============================] - 44s 340ms/step - loss: 1.0578 - acc: 0.4244 - val_loss: 2.1997 - val_acc: 0.3195\n",
      "Epoch 10/10\n",
      "130/130 [==============================] - 41s 313ms/step - loss: 0.9997 - acc: 0.4364 - val_loss: 2.1736 - val_acc: 0.3249\n"
     ]
    }
   ],
   "source": [
    "history3 = training_model.fit(generate_batch(), \n",
    "                    steps_per_epoch=train_samples//batch_size, \n",
    "                    epochs = 10,\n",
    "                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n",
    "                    validation_steps = val_samples // batch_size, \n",
    "                    verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_model():\n",
    "    # x_inputs defined above as Input\n",
    "    # h_enc, s_enc, c_enc also defined above\n",
    "    encoder_model = Model(inputs = x_inputs, outputs = [h_enc, s_enc, c_enc])\n",
    "    return encoder_model\n",
    "\n",
    "def decoder_model():\n",
    "    # The below three decoder inputs will come from encoder_model.predict()\n",
    "    decoder_input_h = Input(shape = (Tx, 2*n_h))               # (None, Tx, 2*n_h) \n",
    "    decoder_input_s = Input(shape=(n_h, ))                    # (None, n_h) \n",
    "    decoder_input_c = Input(shape = (n_h,))                   # (None, n_h)\n",
    "\n",
    "    # y_emb_2 will be our y_pred at t-1\n",
    "    y_inp_2 = Input(shape = (None,))                        # (None, None) = (m, Ty)\n",
    "    y_emb_2 = y_emb_layer(y_inp_2)                          # (None, None, y_emb_dim) = (m, Ty, y_emb_dim)\n",
    "\n",
    "    # Use decoder_input_s and decoder_input_h to compute context vector\n",
    "    context = one_step_attention(decoder_input_h, decoder_input_s)    # (m, 1, 2*n_h)\n",
    "\n",
    "    # concatenate context with y_emb_2\n",
    "    concat2 = Concatenate(axis = -1)([context, tf.expand_dims(y_emb_2[:,-1,:],1)])                       \n",
    "                                                            # concat2 = (None, 1, 2*n_h + y_emb_dim)\n",
    "\n",
    "    # Feed concat2 as input; decoder_input_s and decoder_input_c as initial state\n",
    "    _, decoder_output_s, decoder_output_c = dec_lstm_layer (\n",
    "                                                            initial_state = [decoder_input_s, decoder_input_c], \n",
    "                                                            inputs = concat2\n",
    "                                                            )     \n",
    "                                                # decoder_output_s = (None, n_s) \n",
    "                                                # decoder_output_c = (None, n_s) \n",
    "\n",
    "\n",
    "    decoder_output_y = output_layer(tf.expand_dims(decoder_output_s,1))           # (None, 1, num_decoder_tokens)\n",
    "\n",
    "    decoder_model = Model(inputs = [decoder_input_h, decoder_input_s, decoder_input_c, y_inp_2],\n",
    "                            outputs = [decoder_output_y, decoder_output_s, decoder_output_c])\n",
    "    return decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = encoder_model()\n",
    "decoder_model = decoder_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_sequence):\n",
    "\n",
    "    # input_sequence = (1, max_len)\n",
    "    \n",
    "    # get hidden states + final hidden state + final cell state from encoder \n",
    "    h_enc_pred, s_enc_pred, c_enc_pred = encoder_model.predict(input_sequence)\n",
    "    \n",
    "    # define y_pred at time 0    \n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0,0] = target_word_index['START_']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "\n",
    "    # initialise hidden state and cell state input for decoder\n",
    "    decoder_s_pred = s_enc_pred                         # (None, n_h) = (m, n_h)\n",
    "    decoder_c_pred = c_enc_pred                         # (None, n_h) = (m, n_h)\n",
    "    \n",
    "    while not stop_condition:\n",
    "        decoder_y_pred, decoder_s_pred, decoder_c_pred = decoder_model.predict([h_enc_pred, decoder_s_pred, decoder_c_pred, target_seq])  \n",
    "        y_index = np.argmax(decoder_y_pred[0,-1,:])\n",
    "        y_word = target_index_word[y_index]\n",
    "        decoded_sentence += ' ' + y_word\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (y_word == '_END' or\n",
    "           len(decoded_sentence.split()) > max_len):\n",
    "            stop_condition = True\n",
    "        \n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = y_index\n",
    "        \n",
    "        \n",
    "        \n",
    "    return decoded_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_seq(sentence):\n",
    "    \"\"\"\n",
    "    sentence = string\n",
    "    \"\"\"\n",
    "    \n",
    "    encoder_input_data = np.zeros((1, max_len))     # (1, max_len)\n",
    "    \n",
    "    sentence = sentence.lower().split()\n",
    "    #print(sentence)\n",
    "    for j, word in enumerate(sentence):\n",
    "        encoder_input_data[0,j] = input_word_index[word]        # (1, max_len)\n",
    "    # print(encoder_input_data.shape)\n",
    "    return encoder_input_data                           # (1, max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "WARNING:tensorflow:5 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x1f8b97040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "('the asian part of russia is larger than china', ' die vater ist die haus ist _END')\n",
      "('were conservative', ' sie ist _END')\n",
      "('we live in the age of technology', ' er ist die paar haus _END')\n",
      "('my brother is stupid', ' sie ist ein sehr _END')\n",
      "('tom spent much of his time reading', ' tom hat die paar haus _END')\n",
      "('mary doesnt like men who look like tom', ' er hat tom nicht tom nicht _END')\n",
      "('tom quickly changed the subject', ' tom hat die sehr sehr _END')\n",
      "('she is certain to come on time', ' sie ist die arbeit zu _END')\n",
      "('please listen to us', ' wir ist das _END')\n",
      "('this amount includes tax', ' sie ist ein sehr _END')\n"
     ]
    }
   ],
   "source": [
    "sentences = list(X_train.iloc[:10].values)          # list of sentences\n",
    "\n",
    "translations = []\n",
    "for sentence in sentences:\n",
    "    seq = sentence_to_seq(sentence)             # seq = (1, max_len)\n",
    "    #print(seq, seq.shape)\n",
    "    translation = decode_sequence(seq)\n",
    "    translations.append(translation)\n",
    "\n",
    "sentence_translation_pairs = zip (sentences, translations)\n",
    "for elem in sentence_translation_pairs:\n",
    "    print (elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('the asian part of russia is larger than china', ' der katze ist in dem zimmer ist als _END')\n",
      "('were conservative', ' wir sind _END')\n",
      "('we live in the age of technology', ' wir haben die straße des wand _END')\n",
      "('my brother is stupid', ' mein vater ist sehr _END')\n",
      "('tom spent much of his time reading', ' tom hat mit einer woche mit tom _END')\n",
      "('mary doesnt like men who look like tom', ' tom hat maria nicht wie maria haben _END')\n",
      "('tom quickly changed the subject', ' tom hat sich die ganzen leben zu sein _END')\n",
      "('she is certain to come on time', ' sie hat sich nicht zu zu gehen _END')\n",
      "('please listen to us', ' bitte bitte uns zu _END')\n",
      "('this amount includes tax', ' das haus ist in diesem zimmer _END')\n"
     ]
    }
   ],
   "source": [
    "sentences = list(X_train.iloc[:10].values)          # list of sentences\n",
    "\n",
    "translations = []\n",
    "for sentence in sentences:\n",
    "    seq = sentence_to_seq(sentence)             # seq = (1, max_len)\n",
    "    #print(seq, seq.shape)\n",
    "    translation = decode_sequence(seq)\n",
    "    translations.append(translation)\n",
    "\n",
    "sentence_translation_pairs = zip (sentences, translations)\n",
    "for elem in sentence_translation_pairs:\n",
    "    print (elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('the asian part of russia is larger than china', ' der dieb des landes des feuers ist größer _END')\n",
      "('were conservative', ' wir sind spontan _END')\n",
      "('we live in the age of technology', ' wir leben im zeitalter der treppe _END')\n",
      "('my brother is stupid', ' mein bruder ist wütend _END')\n",
      "('tom spent much of his time reading', ' tom hat viel zeit mit lange zeit _END')\n",
      "('mary doesnt like men who look like tom', ' tom liebt die plan ist uns wie tom _END')\n",
      "('tom quickly changed the subject', ' tom hat seine gefühle nicht die geduld _END')\n",
      "('she is certain to come on time', ' sie ist offensichtlich dass sie da kommt _END')\n",
      "('please listen to us', ' bitte hör uns zu _END')\n",
      "('this amount includes tax', ' in diesem betrag ist die grenze _END')\n"
     ]
    }
   ],
   "source": [
    "sentences = list(X_train.iloc[:10].values)          # list of sentences\n",
    "\n",
    "translations = []\n",
    "for sentence in sentences:\n",
    "    seq = sentence_to_seq(sentence)             # seq = (1, max_len)\n",
    "    #print(seq, seq.shape)\n",
    "    translation = decode_sequence(seq)\n",
    "    translations.append(translation)\n",
    "\n",
    "sentence_translation_pairs = zip (sentences, translations)\n",
    "for elem in sentence_translation_pairs:\n",
    "    print (elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('deep_learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "62f0de500e91648e2f1c8ecd59ca95f97588cc062e27f09a44618e0428f97b74"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
